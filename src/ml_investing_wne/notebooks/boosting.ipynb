{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "build_model for keras_tuner_CNN_LSTM not implemented!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mlflow.keras\n",
    "import pandas as pd\n",
    "\n",
    "from ml_investing_wne import config\n",
    "from ml_investing_wne.utils import get_logger\n",
    "from ml_investing_wne.experiment_factory import create_asset, experiment_factory\n",
    "\n",
    "random.seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "tf.random.set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETHUSDT\n",
      "1440min\n"
     ]
    }
   ],
   "source": [
    "print(config.currency)\n",
    "print(config.freq) \n",
    "asset = create_asset()\n",
    "experiment= experiment_factory(asset).get_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025\n",
      "range_bar\n"
     ]
    }
   ],
   "source": [
    "print(config.fixed_barrier)\n",
    "print(config.RUN_SUBTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "open             float64\n",
       "high             float64\n",
       "low              float64\n",
       "close            float64\n",
       "volume           float64\n",
       "y_pred           float64\n",
       "EMA_5            float64\n",
       "VAR_5            float64\n",
       "EMA_10           float64\n",
       "VAR_10           float64\n",
       "EMA_15           float64\n",
       "VAR_15           float64\n",
       "EMA_20           float64\n",
       "VAR_20           float64\n",
       "EMA_50           float64\n",
       "VAR_50           float64\n",
       "MACD_12_26_9     float64\n",
       "MACDh_12_26_9    float64\n",
       "MACDs_12_26_9    float64\n",
       "RSI_14           float64\n",
       "RSI_10           float64\n",
       "RSI_6            float64\n",
       "STOCHk_14_3_3    float64\n",
       "STOCHd_14_3_3    float64\n",
       "WILLR_14         float64\n",
       "BBL_5_2.0        float64\n",
       "BBM_5_2.0        float64\n",
       "BBU_5_2.0        float64\n",
       "BBB_5_2.0        float64\n",
       "BBP_5_2.0        float64\n",
       "roc_1            float64\n",
       "CMF_20           float64\n",
       "MFI_14           float64\n",
       "hour_sin         float64\n",
       "hour_cos         float64\n",
       "weekday_sin      float64\n",
       "weekday_cos      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change all column types to numeric\n",
    "experiment.df = experiment.df.apply(pd.to_numeric, errors='ignore')\n",
    "experiment.df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>EMA_5</th>\n",
       "      <th>VAR_5</th>\n",
       "      <th>EMA_10</th>\n",
       "      <th>VAR_10</th>\n",
       "      <th>...</th>\n",
       "      <th>BBU_5_2.0</th>\n",
       "      <th>BBB_5_2.0</th>\n",
       "      <th>BBP_5_2.0</th>\n",
       "      <th>roc_1</th>\n",
       "      <th>CMF_20</th>\n",
       "      <th>MFI_14</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>weekday_sin</th>\n",
       "      <th>weekday_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-02 02:39:00</th>\n",
       "      <td>865.02</td>\n",
       "      <td>867.65</td>\n",
       "      <td>849.0</td>\n",
       "      <td>852.53</td>\n",
       "      <td>1855.45604</td>\n",
       "      <td>1.014510</td>\n",
       "      <td>866.759675</td>\n",
       "      <td>178.79567</td>\n",
       "      <td>866.180627</td>\n",
       "      <td>108.88224</td>\n",
       "      <td>...</td>\n",
       "      <td>895.447577</td>\n",
       "      <td>5.489113</td>\n",
       "      <td>0.102878</td>\n",
       "      <td>-0.014439</td>\n",
       "      <td>0.120272</td>\n",
       "      <td>42.802232</td>\n",
       "      <td>0.519584</td>\n",
       "      <td>0.854419</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02 02:51:00</th>\n",
       "      <td>852.53</td>\n",
       "      <td>865.00</td>\n",
       "      <td>840.0</td>\n",
       "      <td>864.90</td>\n",
       "      <td>2825.66757</td>\n",
       "      <td>0.984172</td>\n",
       "      <td>866.139784</td>\n",
       "      <td>181.18858</td>\n",
       "      <td>865.947785</td>\n",
       "      <td>116.15549</td>\n",
       "      <td>...</td>\n",
       "      <td>893.553108</td>\n",
       "      <td>5.538776</td>\n",
       "      <td>0.405021</td>\n",
       "      <td>0.014510</td>\n",
       "      <td>0.224086</td>\n",
       "      <td>55.837665</td>\n",
       "      <td>0.519584</td>\n",
       "      <td>0.854419</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high    low   close      volume    y_pred  \\\n",
       "datetime                                                                   \n",
       "2018-01-02 02:39:00  865.02  867.65  849.0  852.53  1855.45604  1.014510   \n",
       "2018-01-02 02:51:00  852.53  865.00  840.0  864.90  2825.66757  0.984172   \n",
       "\n",
       "                          EMA_5      VAR_5      EMA_10     VAR_10  ...  \\\n",
       "datetime                                                           ...   \n",
       "2018-01-02 02:39:00  866.759675  178.79567  866.180627  108.88224  ...   \n",
       "2018-01-02 02:51:00  866.139784  181.18858  865.947785  116.15549  ...   \n",
       "\n",
       "                      BBU_5_2.0  BBB_5_2.0  BBP_5_2.0     roc_1    CMF_20  \\\n",
       "datetime                                                                    \n",
       "2018-01-02 02:39:00  895.447577   5.489113   0.102878 -0.014439  0.120272   \n",
       "2018-01-02 02:51:00  893.553108   5.538776   0.405021  0.014510  0.224086   \n",
       "\n",
       "                        MFI_14  hour_sin  hour_cos  weekday_sin  weekday_cos  \n",
       "datetime                                                                      \n",
       "2018-01-02 02:39:00  42.802232  0.519584  0.854419     0.866025          0.5  \n",
       "2018-01-02 02:51:00  55.837665  0.519584  0.854419     0.866025          0.5  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.df.to_csv('ETHUSDT_rangebar001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment.df.drop(columns=['to_keep'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = experiment.df[experiment.df.index < config.train_end]\n",
    "val = experiment.df[(experiment.df.index >= config.train_end) & (experiment.df.index < config.val_end)]\n",
    "test = experiment.df[experiment.df.index >= config.val_end]\n",
    "train_val = experiment.df[experiment.df.index < config.val_end]\n",
    "train_test = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.where(train.index < config.train_end, -1, 0)\n",
    "val_indices = np.where(val.index < config.val_end, 0, 1)\n",
    "test_indices = np.where(test.index >= config.val_end, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ...  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "split_indices = np.append(train_indices, val_indices)\n",
    "# split_indices = np.append(train_indices, test_indices)\n",
    "print(split_indices)\n",
    "ps = PredefinedSplit(test_fold=split_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[    0     1     2 ... 18560 18561 18562]\n",
      "  Test:  index=[18563 18564 18565 ... 20980 20981 20982]\n"
     ]
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(ps.split()):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28276,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True, drop=True)\n",
    "val.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20983"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0] + val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def xgboost_tuning(train, val):\n",
    "    # Split the data into training and validation sets\n",
    "    y_train = train['y_pred']\n",
    "    X_train = train.drop(['y_pred'], axis=1)\n",
    "    y_val = val['y_pred']\n",
    "    X_val = val.drop(['y_pred'], axis=1)\n",
    "    \n",
    "    # Define the hyperparameters to tune\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'gamma': [0, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    # Create a GridSearchCV object\n",
    "    cv = GridSearchCV(xgb.XGBClassifier(), param_grid, scoring='accuracy', cv=ps, n_jobs=-1)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    cv.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the validation data\n",
    "    val_pred = cv.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, val_pred)\n",
    "\n",
    "    # Print the best parameters and validation accuracy\n",
    "    print(cv.best_params_)\n",
    "    print(val_accuracy)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost_tuning(train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type...\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.8, 0.9, 1.0],\n",
       "                                        &#x27;gamma&#x27;: [0, 0.1, 0.2],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 6, 7],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                                        &#x27;reg_alpha&#x27;: [0.0, 0.1, 0.2],\n",
       "                                        &#x27;reg_lambda&#x27;: [0.0, 0.1, 0.2],\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.7, 1.0]},\n",
       "                   refit=False, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type...\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.8, 0.9, 1.0],\n",
       "                                        &#x27;gamma&#x27;: [0, 0.1, 0.2],\n",
       "                                        &#x27;learning_rate&#x27;: [0.01, 0.05, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [3, 4, 5, 6, 7],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300],\n",
       "                                        &#x27;reg_alpha&#x27;: [0.0, 0.1, 0.2],\n",
       "                                        &#x27;reg_lambda&#x27;: [0.0, 0.1, 0.2],\n",
       "                                        &#x27;subsample&#x27;: [0.5, 0.7, 1.0]},\n",
       "                   refit=False, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type...\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.8, 0.9, 1.0],\n",
       "                                        'gamma': [0, 0.1, 0.2],\n",
       "                                        'learning_rate': [0.01, 0.05, 0.1],\n",
       "                                        'max_depth': [3, 4, 5, 6, 7],\n",
       "                                        'n_estimators': [100, 200, 300],\n",
       "                                        'reg_alpha': [0.0, 0.1, 0.2],\n",
       "                                        'reg_lambda': [0.0, 0.1, 0.2],\n",
       "                                        'subsample': [0.5, 0.7, 1.0]},\n",
       "                   refit=False, scoring='accuracy')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_val = train_val['y_pred']\n",
    "X_train_val = train_val.drop(['y_pred'], axis=1)\n",
    "y_train = train['y_pred']\n",
    "X_train = train.drop(['y_pred'], axis=1)\n",
    "y_val = val['y_pred']\n",
    "X_val = val.drop(['y_pred'], axis=1)\n",
    "# Define the hyperparameters to tune\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0.0, 0.1, 0.2],\n",
    "    'reg_lambda': [0.0, 0.1, 0.2]\n",
    "}\n",
    "# Create a RandomizedSearchCV object\n",
    "cv = RandomizedSearchCV(xgb.XGBClassifier(), param_distributions, scoring='accuracy', n_iter=10, cv=ps, n_jobs=-1, refit=False)\n",
    "# Fit the model to the training data\n",
    "cv.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 1.0,\n",
       " 'reg_lambda': 0.0,\n",
       " 'reg_alpha': 0.2,\n",
       " 'n_estimators': 300,\n",
       " 'max_depth': 3,\n",
       " 'learning_rate': 0.01,\n",
       " 'gamma': 0.2,\n",
       " 'colsample_bytree': 0.9}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = cv.best_params_\n",
    "best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.9, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.2, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf = xgb.XGBClassifier(objective='binary:logistic', **best_params)\n",
    "xg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([20.32732797,  9.95065188, 11.92745209, 15.69356608,  7.14125681,\n",
       "        10.64880109, 20.45348573,  7.196805  ,  5.75219107, 10.76335073]),\n",
       " 'std_fit_time': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'mean_score_time': array([0.01366091, 0.00518298, 0.00669503, 0.00946999, 0.00586128,\n",
       "        0.00643206, 0.01056623, 0.00521302, 0.00447106, 0.00776815]),\n",
       " 'std_score_time': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'param_subsample': masked_array(data=[0.5, 1.0, 0.7, 0.7, 0.5, 0.5, 1.0, 0.7, 0.7, 0.5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_reg_lambda': masked_array(data=[0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.2, 0.1, 0.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_reg_alpha': masked_array(data=[0.0, 0.2, 0.2, 0.2, 0.2, 0.1, 0.0, 0.1, 0.1, 0.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[300, 300, 300, 200, 100, 200, 300, 100, 100, 200],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[7, 3, 4, 7, 7, 5, 6, 6, 6, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.05, 0.01, 0.05, 0.05, 0.1, 0.05, 0.1, 0.01, 0.05,\n",
       "                    0.05],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.1, 0.2, 0, 0.2, 0.2, 0.2, 0.1, 0.2, 0.2, 0.2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_colsample_bytree': masked_array(data=[1.0, 0.9, 0.9, 1.0, 0.9, 1.0, 1.0, 1.0, 0.9, 1.0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'subsample': 0.5,\n",
       "   'reg_lambda': 0.0,\n",
       "   'reg_alpha': 0.0,\n",
       "   'n_estimators': 300,\n",
       "   'max_depth': 7,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'reg_lambda': 0.0,\n",
       "   'reg_alpha': 0.2,\n",
       "   'n_estimators': 300,\n",
       "   'max_depth': 3,\n",
       "   'learning_rate': 0.01,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_lambda': 0.0,\n",
       "   'reg_alpha': 0.2,\n",
       "   'n_estimators': 300,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_lambda': 0.2,\n",
       "   'reg_alpha': 0.2,\n",
       "   'n_estimators': 200,\n",
       "   'max_depth': 7,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_lambda': 0.0,\n",
       "   'reg_alpha': 0.2,\n",
       "   'n_estimators': 100,\n",
       "   'max_depth': 7,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_lambda': 0.0,\n",
       "   'reg_alpha': 0.1,\n",
       "   'n_estimators': 200,\n",
       "   'max_depth': 5,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 1.0,\n",
       "   'reg_lambda': 0.0,\n",
       "   'reg_alpha': 0.0,\n",
       "   'n_estimators': 300,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.1,\n",
       "   'gamma': 0.1,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_lambda': 0.2,\n",
       "   'reg_alpha': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 1.0},\n",
       "  {'subsample': 0.7,\n",
       "   'reg_lambda': 0.1,\n",
       "   'reg_alpha': 0.1,\n",
       "   'n_estimators': 100,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 0.9},\n",
       "  {'subsample': 0.5,\n",
       "   'reg_lambda': 0.0,\n",
       "   'reg_alpha': 0.0,\n",
       "   'n_estimators': 200,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.05,\n",
       "   'gamma': 0.2,\n",
       "   'colsample_bytree': 1.0}],\n",
       " 'split0_test_score': array([0.53966942, 0.54834711, 0.5285124 , 0.51694215, 0.52024793,\n",
       "        0.5214876 , 0.51942149, 0.51363636, 0.51983471, 0.53305785]),\n",
       " 'mean_test_score': array([0.53966942, 0.54834711, 0.5285124 , 0.51694215, 0.52024793,\n",
       "        0.5214876 , 0.51942149, 0.51363636, 0.51983471, 0.53305785]),\n",
       " 'std_test_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'rank_test_score': array([ 2,  1,  4,  9,  6,  5,  8, 10,  7,  3], dtype=int32)}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_hyperparameters(cv_results, n):\n",
    "    results = pd.DataFrame(cv_results)\n",
    "    results = results.sort_values(by='rank_test_score')\n",
    "    return results[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_reg_lambda</th>\n",
       "      <th>param_reg_alpha</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.950652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'subsample': 1.0, 'reg_lambda': 0.0, 'reg_alp...</td>\n",
       "      <td>0.548347</td>\n",
       "      <td>0.548347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.327328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300</td>\n",
       "      <td>7</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'subsample': 0.5, 'reg_lambda': 0.0, 'reg_alp...</td>\n",
       "      <td>0.539669</td>\n",
       "      <td>0.539669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.763351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'subsample': 0.5, 'reg_lambda': 0.0, 'reg_alp...</td>\n",
       "      <td>0.533058</td>\n",
       "      <td>0.533058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.927452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'subsample': 0.7, 'reg_lambda': 0.0, 'reg_alp...</td>\n",
       "      <td>0.528512</td>\n",
       "      <td>0.528512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.648801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'subsample': 0.5, 'reg_lambda': 0.0, 'reg_alp...</td>\n",
       "      <td>0.521488</td>\n",
       "      <td>0.521488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "1       9.950652           0.0         0.005183             0.0   \n",
       "0      20.327328           0.0         0.013661             0.0   \n",
       "9      10.763351           0.0         0.007768             0.0   \n",
       "2      11.927452           0.0         0.006695             0.0   \n",
       "5      10.648801           0.0         0.006432             0.0   \n",
       "\n",
       "  param_subsample param_reg_lambda param_reg_alpha param_n_estimators  \\\n",
       "1             1.0              0.0             0.2                300   \n",
       "0             0.5              0.0             0.0                300   \n",
       "9             0.5              0.0             0.0                200   \n",
       "2             0.7              0.0             0.2                300   \n",
       "5             0.5              0.0             0.1                200   \n",
       "\n",
       "  param_max_depth param_learning_rate param_gamma param_colsample_bytree  \\\n",
       "1               3                0.01         0.2                    0.9   \n",
       "0               7                0.05         0.1                    1.0   \n",
       "9               6                0.05         0.2                    1.0   \n",
       "2               4                0.05           0                    0.9   \n",
       "5               5                0.05         0.2                    1.0   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "1  {'subsample': 1.0, 'reg_lambda': 0.0, 'reg_alp...           0.548347   \n",
       "0  {'subsample': 0.5, 'reg_lambda': 0.0, 'reg_alp...           0.539669   \n",
       "9  {'subsample': 0.5, 'reg_lambda': 0.0, 'reg_alp...           0.533058   \n",
       "2  {'subsample': 0.7, 'reg_lambda': 0.0, 'reg_alp...           0.528512   \n",
       "5  {'subsample': 0.5, 'reg_lambda': 0.0, 'reg_alp...           0.521488   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "1         0.548347             0.0                1  \n",
       "0         0.539669             0.0                2  \n",
       "9         0.533058             0.0                3  \n",
       "2         0.528512             0.0                4  \n",
       "5         0.521488             0.0                5  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_hyperparameters(cv.cv_results_, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 Hyperparameters:\n",
      "subsample: 1.0\n",
      "reg_lambda: 0.0\n",
      "reg_alpha: 0.2\n",
      "n_estimators: 300\n",
      "max_depth: 3\n",
      "learning_rate: 0.01\n",
      "gamma: 0.2\n",
      "colsample_bytree: 0.9\n",
      "Mean Validation Score: 0.5483\n",
      "==============================\n",
      "Top 2 Hyperparameters:\n",
      "subsample: 1.0\n",
      "reg_lambda: 0.0\n",
      "reg_alpha: 0.2\n",
      "n_estimators: 300\n",
      "max_depth: 3\n",
      "learning_rate: 0.01\n",
      "gamma: 0.2\n",
      "colsample_bytree: 0.9\n",
      "Mean Validation Score: 0.5483\n",
      "==============================\n",
      "Top 3 Hyperparameters:\n",
      "subsample: 1.0\n",
      "reg_lambda: 0.0\n",
      "reg_alpha: 0.2\n",
      "n_estimators: 300\n",
      "max_depth: 3\n",
      "learning_rate: 0.01\n",
      "gamma: 0.2\n",
      "colsample_bytree: 0.9\n",
      "Mean Validation Score: 0.5483\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "results = cv.cv_results_\n",
    "for i in range(3):\n",
    "    print(f\"Top {i+1} Hyperparameters:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    print(f\"Mean Validation Score: {results['mean_test_score'][cv.best_index_]:.4f}\")\n",
    "    print(\"=\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_tuning_random(train_val, train, val, n_experiments=10, ps=ps):\n",
    "\n",
    "\n",
    "    y_train_val = train_val['y_pred']\n",
    "    X_train_val = train_val.drop(['y_pred'], axis=1)\n",
    "    y_train = train['y_pred']\n",
    "    X_train = train.drop(['y_pred'], axis=1)\n",
    "    y_val = val['y_pred']\n",
    "    X_val = val.drop(['y_pred'], axis=1)\n",
    "\n",
    "    # Define the hyperparameters to tune\n",
    "    param_distributions = {\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 4, 5, 6, 7],\n",
    "        'gamma': [0, 0.1, 0.2],\n",
    "        'subsample': [0.5, 0.7, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "        'reg_alpha': [0.0, 0.1, 0.2],\n",
    "        'reg_lambda': [0.0, 0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    # Create a RandomizedSearchCV object\n",
    "    cv = RandomizedSearchCV(xgb.XGBClassifier(), param_distributions, scoring='accuracy', n_iter=n_experiments, cv=ps, n_jobs=-1, refit=False)\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    cv.fit(X_train_val, y_train_val)\n",
    "\n",
    "    # Evaluate the model on the validation data\n",
    "    val_pred = cv.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, val_pred)\n",
    "\n",
    "    # Print the best parameters and validation accuracy\n",
    "    print(cv.best_params_)\n",
    "    print(val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "This RandomizedSearchCV instance was initialized with `refit=False`. predict is available only after refitting on the best parameters. You can refit an estimator manually using the `best_params_` attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/i0495036/Documents/sandbox/ml_investing_wne/src/ml_investing_wne/notebooks/boosting.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/i0495036/Documents/sandbox/ml_investing_wne/src/ml_investing_wne/notebooks/boosting.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xgboost_tuning_random(train_val, train, val, n_experiments\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "\u001b[1;32m/Users/i0495036/Documents/sandbox/ml_investing_wne/src/ml_investing_wne/notebooks/boosting.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/i0495036/Documents/sandbox/ml_investing_wne/src/ml_investing_wne/notebooks/boosting.ipynb#X20sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m cv\u001b[39m.\u001b[39mfit(X_train_val, y_train_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/i0495036/Documents/sandbox/ml_investing_wne/src/ml_investing_wne/notebooks/boosting.ipynb#X20sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Evaluate the model on the validation data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/i0495036/Documents/sandbox/ml_investing_wne/src/ml_investing_wne/notebooks/boosting.ipynb#X20sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m val_pred \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39;49mpredict(X_val)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/i0495036/Documents/sandbox/ml_investing_wne/src/ml_investing_wne/notebooks/boosting.ipynb#X20sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m val_accuracy \u001b[39m=\u001b[39m accuracy_score(y_val, val_pred)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/i0495036/Documents/sandbox/ml_investing_wne/src/ml_investing_wne/notebooks/boosting.ipynb#X20sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Print the best parameters and validation accuracy\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/sklearn/utils/_available_if.py:32\u001b[0m, in \u001b[0;36m_AvailableIfDescriptor.__get__\u001b[0;34m(self, obj, owner)\u001b[0m\n\u001b[1;32m     26\u001b[0m attr_err \u001b[39m=\u001b[39m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(owner\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattribute_name)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[39m# delegate only on instances, not the classes.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[39m# this is to allow access to the docstrings.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck(obj):\n\u001b[1;32m     33\u001b[0m         \u001b[39mraise\u001b[39;00m attr_err\n\u001b[1;32m     34\u001b[0m     out \u001b[39m=\u001b[39m MethodType(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn, obj)\n",
      "File \u001b[0;32m~/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py:359\u001b[0m, in \u001b[0;36m_estimator_has.<locals>.check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 359\u001b[0m     _check_refit(\u001b[39mself\u001b[39;49m, attr)\n\u001b[1;32m    360\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mbest_estimator_\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    361\u001b[0m         \u001b[39m# raise an AttributeError if `attr` does not exist\u001b[39;00m\n\u001b[1;32m    362\u001b[0m         \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_, attr)\n",
      "File \u001b[0;32m~/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/sklearn/model_selection/_search.py:339\u001b[0m, in \u001b[0;36m_check_refit\u001b[0;34m(search_cv, attr)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_refit\u001b[39m(search_cv, attr):\n\u001b[1;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m search_cv\u001b[39m.\u001b[39mrefit:\n\u001b[0;32m--> 339\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(search_cv)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m instance was initialized with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`refit=False`. \u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m is available only after refitting on the best \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mparameters. You can refit an estimator manually using the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    343\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`best_params_` attribute\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    344\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: This RandomizedSearchCV instance was initialized with `refit=False`. predict is available only after refitting on the best parameters. You can refit an estimator manually using the `best_params_` attribute"
     ]
    }
   ],
   "source": [
    "xgboost_tuning_random(train_val, train, val, n_experiments=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 180\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['y_pred']\n",
    "X_train = train.drop(['y_pred'], axis=1)\n",
    "y_val = val['y_pred']\n",
    "X_val = val.drop(['y_pred'], axis=1)\n",
    "\n",
    "def hyperparameter_tuning(space):\n",
    "    \n",
    "   \n",
    "    model = xgb.XGBClassifier(n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                         reg_alpha = int(space['reg_alpha']) ,min_child_weight=space['min_child_weight'],\n",
    "                         colsample_bytree=space['colsample_bytree'])\n",
    "    evaluation = [( X_train, y_train), ( X_val, y_val)]\n",
    "    \n",
    "    model.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"rmse\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "\n",
    "    pred = model.predict(X_train)\n",
    "    accuracy = accuracy_score(y_train, pred>0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    #change the metric if you like\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                \n",
      "0.572213543069547                                     \n",
      "  5%|â–Œ         | 1/20 [00:00<00:04,  4.63trial/s, best loss: -0.572213543069547]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                          \n",
      "0.5325109087970694                                                              \n",
      " 10%|â–ˆ         | 2/20 [00:00<00:04,  3.80trial/s, best loss: -0.572213543069547]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                          \n",
      "0.528416742983354                                                               \n",
      " 15%|â–ˆâ–Œ        | 3/20 [00:00<00:04,  4.04trial/s, best loss: -0.572213543069547]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                          \n",
      "0.584118946291009                                                               \n",
      "SCORE:                                                                          \n",
      "0.5421537467004256                                                              \n",
      " 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.93trial/s, best loss: -0.584118946291009]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                          \n",
      "0.567419059419275                                                               \n",
      "SCORE:                                                                          \n",
      "0.5567526800624899                                                              \n",
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.45trial/s, best loss: -0.584118946291009]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                          \n",
      "0.5218445294402845                                                              \n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.32trial/s, best loss: -0.584118946291009]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                          \n",
      "0.6105155416689113                                                              \n",
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:02<00:02,  4.33trial/s, best loss: -0.6105155416689113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                           \n",
      "0.5621936109465064                                                               \n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  3.76trial/s, best loss: -0.6105155416689113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.556860421268114                                                                 \n",
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:02,  3.44trial/s, best loss: -0.6105155416689113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.5413995582610569                                                                \n",
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:03<00:02,  3.09trial/s, best loss: -0.6105155416689113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.5773312503366913                                                                \n",
      "SCORE:                                                                            \n",
      "0.5347734741151754                                                                \n",
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  3.08trial/s, best loss: -0.6105155416689113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.578247050584496                                                                 \n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:04<00:01,  2.76trial/s, best loss: -0.6105155416689113]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.6237677099606744                                                                \n",
      "SCORE:                                                                            \n",
      "0.5325109087970694                                                                \n",
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:04<00:00,  3.18trial/s, best loss: -0.6237677099606744]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.5566988094596779                                                                \n",
      "SCORE:                                                                            \n",
      "0.5312718849323924                                                                \n",
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:05<00:00,  3.80trial/s, best loss: -0.6237677099606744]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n",
      "/Users/i0495036/Documents/sandbox/ml_investing_wne/.conda/lib/python3.8/site-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                                            \n",
      "0.5218445294402845                                                                \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:05<00:00,  3.69trial/s, best loss: -0.6237677099606744]\n",
      "{'colsample_bytree': 0.9281176550626448, 'gamma': 2.804787618655417, 'max_depth': 5.0, 'min_child_weight': 4.0, 'reg_alpha': 44.0, 'reg_lambda': 0.7368387962350481}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=hyperparameter_tuning,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)\n",
    "\n",
    "print (best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'subsample': 0.7, 'reg_lambda': 0.0, 'reg_alpha': 0.1, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 0.5}\n",
    "# 0.51007326007326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'subsample': 0.5, 'reg_lambda': 0.1, 'reg_alpha': 0.2, 'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.1, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_classifier = xgb.XGBClassifier(**hyperparameters)\n",
    "xgboost_classifier.fit(train_val.drop(['y_pred'], axis=1), train_val['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tripple barrier no stride\n",
    "# {'subsample': 0.7, 'reg_lambda': 0.2, 'reg_alpha': 0.0, 'n_estimators': 300, 'max_depth': 7, 'learning_rate': 0.05, 'gamma': 0, 'colsample_bytree': 1.0}\n",
    "# 0.48097826086956524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.4895500875115824\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgboost_classifier.predict_proba(test.drop(['y_pred'], axis=1))\n",
    "accuracy = accuracy_score(test['y_pred'], y_pred[:,1]>0.5)\n",
    "print (\"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8309917355371901\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = xgboost_classifier.predict_proba(val.drop(['y_pred'], axis=1))\n",
    "accuracy = accuracy_score(val['y_pred'], y_pred_val[:,1]>0.5)\n",
    "print (\"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.837687873727307\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = xgboost_classifier.predict_proba(train.drop(['y_pred'], axis=1))\n",
    "accuracy = accuracy_score(train['y_pred'], y_pred_train[:,1]>0.5)\n",
    "print (\"accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(test['y_pred'], y_pred[:,1])\n",
    "# precision, recall, thresholds = precision_recall_curve(val['y_pred'], y_pred_val[:,1])\n",
    "# precision, recall, thresholds = precision_recall_curve(train['y_pred'], y_pred_train[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Train Precision-Recall curve')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.fill_between(recall, precision)\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.title(\"Train Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('codeserver_py39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca522a4f3a95a8cc19c0c49aa2b52717208ab4d9caac282bf163cf809ab5536"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
