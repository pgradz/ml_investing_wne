{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide GPU from tensorflow\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 19:16:59.925924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-01 19:17:00.585227: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mlflow.keras\n",
    "\n",
    "from ml_investing_wne import config\n",
    "from ml_investing_wne.utils import get_logger\n",
    "from ml_investing_wne.experiment_factory import create_asset, experiment_factory\n",
    "\n",
    "random.seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "tf.random.set_seed(config.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 19:17:02.167979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 19:17:02.173921: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 19:17:02.174118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.currency = 'BTCUSDT'\n",
    "btc = create_asset()\n",
    "experiment_btc = experiment_factory(btc).get_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>SMA_5</th>\n",
       "      <th>EMA_5</th>\n",
       "      <th>VAR_5</th>\n",
       "      <th>SMA_10</th>\n",
       "      <th>...</th>\n",
       "      <th>BBU_5_2.0</th>\n",
       "      <th>BBB_5_2.0</th>\n",
       "      <th>BBP_5_2.0</th>\n",
       "      <th>roc_1</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>weekday_sin</th>\n",
       "      <th>weekday_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:05:00</th>\n",
       "      <td>13447.73</td>\n",
       "      <td>13455.05</td>\n",
       "      <td>13370.00</td>\n",
       "      <td>13400.00</td>\n",
       "      <td>20.443116</td>\n",
       "      <td>0.996396</td>\n",
       "      <td>13432.584</td>\n",
       "      <td>13429.360310</td>\n",
       "      <td>1226.42003</td>\n",
       "      <td>13477.047</td>\n",
       "      <td>...</td>\n",
       "      <td>13495.230182</td>\n",
       "      <td>0.932750</td>\n",
       "      <td>0.239936</td>\n",
       "      <td>-0.002007</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:10:00</th>\n",
       "      <td>13399.99</td>\n",
       "      <td>13427.48</td>\n",
       "      <td>13322.15</td>\n",
       "      <td>13351.71</td>\n",
       "      <td>32.528288</td>\n",
       "      <td>0.998378</td>\n",
       "      <td>13404.934</td>\n",
       "      <td>13403.476873</td>\n",
       "      <td>1082.91653</td>\n",
       "      <td>13461.218</td>\n",
       "      <td>...</td>\n",
       "      <td>13463.801078</td>\n",
       "      <td>0.878290</td>\n",
       "      <td>0.047931</td>\n",
       "      <td>-0.003604</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:15:00</th>\n",
       "      <td>13354.99</td>\n",
       "      <td>13389.98</td>\n",
       "      <td>13323.55</td>\n",
       "      <td>13330.05</td>\n",
       "      <td>36.474570</td>\n",
       "      <td>1.005922</td>\n",
       "      <td>13383.748</td>\n",
       "      <td>13379.001249</td>\n",
       "      <td>1682.79812</td>\n",
       "      <td>13437.986</td>\n",
       "      <td>...</td>\n",
       "      <td>13457.130246</td>\n",
       "      <td>1.096587</td>\n",
       "      <td>0.134121</td>\n",
       "      <td>-0.001622</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:20:00</th>\n",
       "      <td>13336.98</td>\n",
       "      <td>13410.00</td>\n",
       "      <td>13331.00</td>\n",
       "      <td>13408.99</td>\n",
       "      <td>17.610242</td>\n",
       "      <td>1.001567</td>\n",
       "      <td>13383.540</td>\n",
       "      <td>13388.997499</td>\n",
       "      <td>1669.34780</td>\n",
       "      <td>13419.887</td>\n",
       "      <td>...</td>\n",
       "      <td>13456.628391</td>\n",
       "      <td>1.092213</td>\n",
       "      <td>0.674104</td>\n",
       "      <td>0.005922</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:25:00</th>\n",
       "      <td>13408.99</td>\n",
       "      <td>13449.89</td>\n",
       "      <td>13391.31</td>\n",
       "      <td>13430.00</td>\n",
       "      <td>16.478325</td>\n",
       "      <td>1.001143</td>\n",
       "      <td>13384.150</td>\n",
       "      <td>13402.664999</td>\n",
       "      <td>1737.40855</td>\n",
       "      <td>13418.367</td>\n",
       "      <td>...</td>\n",
       "      <td>13458.713445</td>\n",
       "      <td>1.114205</td>\n",
       "      <td>0.807456</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:30:00</th>\n",
       "      <td>13429.99</td>\n",
       "      <td>13460.90</td>\n",
       "      <td>13401.94</td>\n",
       "      <td>13445.35</td>\n",
       "      <td>24.084508</td>\n",
       "      <td>1.001238</td>\n",
       "      <td>13393.220</td>\n",
       "      <td>13416.893333</td>\n",
       "      <td>2508.13180</td>\n",
       "      <td>13412.902</td>\n",
       "      <td>...</td>\n",
       "      <td>13482.808067</td>\n",
       "      <td>1.337812</td>\n",
       "      <td>0.790943</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:35:00</th>\n",
       "      <td>13446.25</td>\n",
       "      <td>13477.00</td>\n",
       "      <td>13422.16</td>\n",
       "      <td>13462.00</td>\n",
       "      <td>16.370098</td>\n",
       "      <td>1.003373</td>\n",
       "      <td>13415.278</td>\n",
       "      <td>13431.928889</td>\n",
       "      <td>2651.83967</td>\n",
       "      <td>13410.106</td>\n",
       "      <td>...</td>\n",
       "      <td>13507.396874</td>\n",
       "      <td>1.373343</td>\n",
       "      <td>0.753596</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:40:00</th>\n",
       "      <td>13474.00</td>\n",
       "      <td>13550.00</td>\n",
       "      <td>13474.00</td>\n",
       "      <td>13507.41</td>\n",
       "      <td>28.489002</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>13450.750</td>\n",
       "      <td>13457.089259</td>\n",
       "      <td>1385.13455</td>\n",
       "      <td>13417.249</td>\n",
       "      <td>...</td>\n",
       "      <td>13517.326502</td>\n",
       "      <td>0.989930</td>\n",
       "      <td>0.925526</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:45:00</th>\n",
       "      <td>13507.41</td>\n",
       "      <td>13588.99</td>\n",
       "      <td>13480.01</td>\n",
       "      <td>13499.99</td>\n",
       "      <td>33.803913</td>\n",
       "      <td>1.005779</td>\n",
       "      <td>13468.950</td>\n",
       "      <td>13471.389506</td>\n",
       "      <td>1141.25455</td>\n",
       "      <td>13426.245</td>\n",
       "      <td>...</td>\n",
       "      <td>13529.381900</td>\n",
       "      <td>0.897351</td>\n",
       "      <td>0.756818</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:50:00</th>\n",
       "      <td>13499.99</td>\n",
       "      <td>13578.93</td>\n",
       "      <td>13465.41</td>\n",
       "      <td>13578.00</td>\n",
       "      <td>17.436532</td>\n",
       "      <td>1.001695</td>\n",
       "      <td>13498.550</td>\n",
       "      <td>13506.926337</td>\n",
       "      <td>2639.75455</td>\n",
       "      <td>13441.350</td>\n",
       "      <td>...</td>\n",
       "      <td>13590.458730</td>\n",
       "      <td>1.361757</td>\n",
       "      <td>0.932222</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close     volume  \\\n",
       "datetime                                                                 \n",
       "2018-01-01 04:05:00  13447.73  13455.05  13370.00  13400.00  20.443116   \n",
       "2018-01-01 04:10:00  13399.99  13427.48  13322.15  13351.71  32.528288   \n",
       "2018-01-01 04:15:00  13354.99  13389.98  13323.55  13330.05  36.474570   \n",
       "2018-01-01 04:20:00  13336.98  13410.00  13331.00  13408.99  17.610242   \n",
       "2018-01-01 04:25:00  13408.99  13449.89  13391.31  13430.00  16.478325   \n",
       "2018-01-01 04:30:00  13429.99  13460.90  13401.94  13445.35  24.084508   \n",
       "2018-01-01 04:35:00  13446.25  13477.00  13422.16  13462.00  16.370098   \n",
       "2018-01-01 04:40:00  13474.00  13550.00  13474.00  13507.41  28.489002   \n",
       "2018-01-01 04:45:00  13507.41  13588.99  13480.01  13499.99  33.803913   \n",
       "2018-01-01 04:50:00  13499.99  13578.93  13465.41  13578.00  17.436532   \n",
       "\n",
       "                       y_pred      SMA_5         EMA_5       VAR_5     SMA_10  \\\n",
       "datetime                                                                        \n",
       "2018-01-01 04:05:00  0.996396  13432.584  13429.360310  1226.42003  13477.047   \n",
       "2018-01-01 04:10:00  0.998378  13404.934  13403.476873  1082.91653  13461.218   \n",
       "2018-01-01 04:15:00  1.005922  13383.748  13379.001249  1682.79812  13437.986   \n",
       "2018-01-01 04:20:00  1.001567  13383.540  13388.997499  1669.34780  13419.887   \n",
       "2018-01-01 04:25:00  1.001143  13384.150  13402.664999  1737.40855  13418.367   \n",
       "2018-01-01 04:30:00  1.001238  13393.220  13416.893333  2508.13180  13412.902   \n",
       "2018-01-01 04:35:00  1.003373  13415.278  13431.928889  2651.83967  13410.106   \n",
       "2018-01-01 04:40:00  0.999451  13450.750  13457.089259  1385.13455  13417.249   \n",
       "2018-01-01 04:45:00  1.005779  13468.950  13471.389506  1141.25455  13426.245   \n",
       "2018-01-01 04:50:00  1.001695  13498.550  13506.926337  2639.75455  13441.350   \n",
       "\n",
       "                     ...     BBU_5_2.0  BBB_5_2.0  BBP_5_2.0     roc_1  hour  \\\n",
       "datetime             ...                                                       \n",
       "2018-01-01 04:05:00  ...  13495.230182   0.932750   0.239936 -0.002007     4   \n",
       "2018-01-01 04:10:00  ...  13463.801078   0.878290   0.047931 -0.003604     4   \n",
       "2018-01-01 04:15:00  ...  13457.130246   1.096587   0.134121 -0.001622     4   \n",
       "2018-01-01 04:20:00  ...  13456.628391   1.092213   0.674104  0.005922     4   \n",
       "2018-01-01 04:25:00  ...  13458.713445   1.114205   0.807456  0.001567     4   \n",
       "2018-01-01 04:30:00  ...  13482.808067   1.337812   0.790943  0.001143     4   \n",
       "2018-01-01 04:35:00  ...  13507.396874   1.373343   0.753596  0.001238     4   \n",
       "2018-01-01 04:40:00  ...  13517.326502   0.989930   0.925526  0.003373     4   \n",
       "2018-01-01 04:45:00  ...  13529.381900   0.897351   0.756818 -0.000549     4   \n",
       "2018-01-01 04:50:00  ...  13590.458730   1.361757   0.932222  0.005779     4   \n",
       "\n",
       "                     weekday  hour_sin  hour_cos  weekday_sin  weekday_cos  \n",
       "datetime                                                                    \n",
       "2018-01-01 04:05:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:10:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:15:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:20:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:25:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:30:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:35:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:40:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:45:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:50:00        0  0.887885  0.460065          0.0          1.0  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_btc.df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_btc.df['y_pred'] = [1 if y > 1 else 0 for y in  experiment_btc.df['y_pred']]\n",
    "train_examples = experiment_btc.df.drop(columns=['y_pred']).values\n",
    "train_labels = experiment_btc.df['y_pred'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>SMA_5</th>\n",
       "      <th>EMA_5</th>\n",
       "      <th>VAR_5</th>\n",
       "      <th>SMA_10</th>\n",
       "      <th>...</th>\n",
       "      <th>BBU_5_2.0</th>\n",
       "      <th>BBB_5_2.0</th>\n",
       "      <th>BBP_5_2.0</th>\n",
       "      <th>roc_1</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>weekday_sin</th>\n",
       "      <th>weekday_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:05:00</th>\n",
       "      <td>13447.73</td>\n",
       "      <td>13455.05</td>\n",
       "      <td>13370.00</td>\n",
       "      <td>13400.00</td>\n",
       "      <td>20.443116</td>\n",
       "      <td>0</td>\n",
       "      <td>13432.584</td>\n",
       "      <td>13429.360310</td>\n",
       "      <td>1226.42003</td>\n",
       "      <td>13477.047</td>\n",
       "      <td>...</td>\n",
       "      <td>13495.230182</td>\n",
       "      <td>0.932750</td>\n",
       "      <td>0.239936</td>\n",
       "      <td>-0.002007</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:10:00</th>\n",
       "      <td>13399.99</td>\n",
       "      <td>13427.48</td>\n",
       "      <td>13322.15</td>\n",
       "      <td>13351.71</td>\n",
       "      <td>32.528288</td>\n",
       "      <td>0</td>\n",
       "      <td>13404.934</td>\n",
       "      <td>13403.476873</td>\n",
       "      <td>1082.91653</td>\n",
       "      <td>13461.218</td>\n",
       "      <td>...</td>\n",
       "      <td>13463.801078</td>\n",
       "      <td>0.878290</td>\n",
       "      <td>0.047931</td>\n",
       "      <td>-0.003604</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:15:00</th>\n",
       "      <td>13354.99</td>\n",
       "      <td>13389.98</td>\n",
       "      <td>13323.55</td>\n",
       "      <td>13330.05</td>\n",
       "      <td>36.474570</td>\n",
       "      <td>1</td>\n",
       "      <td>13383.748</td>\n",
       "      <td>13379.001249</td>\n",
       "      <td>1682.79812</td>\n",
       "      <td>13437.986</td>\n",
       "      <td>...</td>\n",
       "      <td>13457.130246</td>\n",
       "      <td>1.096587</td>\n",
       "      <td>0.134121</td>\n",
       "      <td>-0.001622</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:20:00</th>\n",
       "      <td>13336.98</td>\n",
       "      <td>13410.00</td>\n",
       "      <td>13331.00</td>\n",
       "      <td>13408.99</td>\n",
       "      <td>17.610242</td>\n",
       "      <td>1</td>\n",
       "      <td>13383.540</td>\n",
       "      <td>13388.997499</td>\n",
       "      <td>1669.34780</td>\n",
       "      <td>13419.887</td>\n",
       "      <td>...</td>\n",
       "      <td>13456.628391</td>\n",
       "      <td>1.092213</td>\n",
       "      <td>0.674104</td>\n",
       "      <td>0.005922</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:25:00</th>\n",
       "      <td>13408.99</td>\n",
       "      <td>13449.89</td>\n",
       "      <td>13391.31</td>\n",
       "      <td>13430.00</td>\n",
       "      <td>16.478325</td>\n",
       "      <td>1</td>\n",
       "      <td>13384.150</td>\n",
       "      <td>13402.664999</td>\n",
       "      <td>1737.40855</td>\n",
       "      <td>13418.367</td>\n",
       "      <td>...</td>\n",
       "      <td>13458.713445</td>\n",
       "      <td>1.114205</td>\n",
       "      <td>0.807456</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:30:00</th>\n",
       "      <td>13429.99</td>\n",
       "      <td>13460.90</td>\n",
       "      <td>13401.94</td>\n",
       "      <td>13445.35</td>\n",
       "      <td>24.084508</td>\n",
       "      <td>1</td>\n",
       "      <td>13393.220</td>\n",
       "      <td>13416.893333</td>\n",
       "      <td>2508.13180</td>\n",
       "      <td>13412.902</td>\n",
       "      <td>...</td>\n",
       "      <td>13482.808067</td>\n",
       "      <td>1.337812</td>\n",
       "      <td>0.790943</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:35:00</th>\n",
       "      <td>13446.25</td>\n",
       "      <td>13477.00</td>\n",
       "      <td>13422.16</td>\n",
       "      <td>13462.00</td>\n",
       "      <td>16.370098</td>\n",
       "      <td>1</td>\n",
       "      <td>13415.278</td>\n",
       "      <td>13431.928889</td>\n",
       "      <td>2651.83967</td>\n",
       "      <td>13410.106</td>\n",
       "      <td>...</td>\n",
       "      <td>13507.396874</td>\n",
       "      <td>1.373343</td>\n",
       "      <td>0.753596</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:40:00</th>\n",
       "      <td>13474.00</td>\n",
       "      <td>13550.00</td>\n",
       "      <td>13474.00</td>\n",
       "      <td>13507.41</td>\n",
       "      <td>28.489002</td>\n",
       "      <td>0</td>\n",
       "      <td>13450.750</td>\n",
       "      <td>13457.089259</td>\n",
       "      <td>1385.13455</td>\n",
       "      <td>13417.249</td>\n",
       "      <td>...</td>\n",
       "      <td>13517.326502</td>\n",
       "      <td>0.989930</td>\n",
       "      <td>0.925526</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:45:00</th>\n",
       "      <td>13507.41</td>\n",
       "      <td>13588.99</td>\n",
       "      <td>13480.01</td>\n",
       "      <td>13499.99</td>\n",
       "      <td>33.803913</td>\n",
       "      <td>1</td>\n",
       "      <td>13468.950</td>\n",
       "      <td>13471.389506</td>\n",
       "      <td>1141.25455</td>\n",
       "      <td>13426.245</td>\n",
       "      <td>...</td>\n",
       "      <td>13529.381900</td>\n",
       "      <td>0.897351</td>\n",
       "      <td>0.756818</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:50:00</th>\n",
       "      <td>13499.99</td>\n",
       "      <td>13578.93</td>\n",
       "      <td>13465.41</td>\n",
       "      <td>13578.00</td>\n",
       "      <td>17.436532</td>\n",
       "      <td>1</td>\n",
       "      <td>13498.550</td>\n",
       "      <td>13506.926337</td>\n",
       "      <td>2639.75455</td>\n",
       "      <td>13441.350</td>\n",
       "      <td>...</td>\n",
       "      <td>13590.458730</td>\n",
       "      <td>1.361757</td>\n",
       "      <td>0.932222</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.887885</td>\n",
       "      <td>0.460065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open      high       low     close     volume  \\\n",
       "datetime                                                                 \n",
       "2018-01-01 04:05:00  13447.73  13455.05  13370.00  13400.00  20.443116   \n",
       "2018-01-01 04:10:00  13399.99  13427.48  13322.15  13351.71  32.528288   \n",
       "2018-01-01 04:15:00  13354.99  13389.98  13323.55  13330.05  36.474570   \n",
       "2018-01-01 04:20:00  13336.98  13410.00  13331.00  13408.99  17.610242   \n",
       "2018-01-01 04:25:00  13408.99  13449.89  13391.31  13430.00  16.478325   \n",
       "2018-01-01 04:30:00  13429.99  13460.90  13401.94  13445.35  24.084508   \n",
       "2018-01-01 04:35:00  13446.25  13477.00  13422.16  13462.00  16.370098   \n",
       "2018-01-01 04:40:00  13474.00  13550.00  13474.00  13507.41  28.489002   \n",
       "2018-01-01 04:45:00  13507.41  13588.99  13480.01  13499.99  33.803913   \n",
       "2018-01-01 04:50:00  13499.99  13578.93  13465.41  13578.00  17.436532   \n",
       "\n",
       "                     y_pred      SMA_5         EMA_5       VAR_5     SMA_10  \\\n",
       "datetime                                                                      \n",
       "2018-01-01 04:05:00       0  13432.584  13429.360310  1226.42003  13477.047   \n",
       "2018-01-01 04:10:00       0  13404.934  13403.476873  1082.91653  13461.218   \n",
       "2018-01-01 04:15:00       1  13383.748  13379.001249  1682.79812  13437.986   \n",
       "2018-01-01 04:20:00       1  13383.540  13388.997499  1669.34780  13419.887   \n",
       "2018-01-01 04:25:00       1  13384.150  13402.664999  1737.40855  13418.367   \n",
       "2018-01-01 04:30:00       1  13393.220  13416.893333  2508.13180  13412.902   \n",
       "2018-01-01 04:35:00       1  13415.278  13431.928889  2651.83967  13410.106   \n",
       "2018-01-01 04:40:00       0  13450.750  13457.089259  1385.13455  13417.249   \n",
       "2018-01-01 04:45:00       1  13468.950  13471.389506  1141.25455  13426.245   \n",
       "2018-01-01 04:50:00       1  13498.550  13506.926337  2639.75455  13441.350   \n",
       "\n",
       "                     ...     BBU_5_2.0  BBB_5_2.0  BBP_5_2.0     roc_1  hour  \\\n",
       "datetime             ...                                                       \n",
       "2018-01-01 04:05:00  ...  13495.230182   0.932750   0.239936 -0.002007     4   \n",
       "2018-01-01 04:10:00  ...  13463.801078   0.878290   0.047931 -0.003604     4   \n",
       "2018-01-01 04:15:00  ...  13457.130246   1.096587   0.134121 -0.001622     4   \n",
       "2018-01-01 04:20:00  ...  13456.628391   1.092213   0.674104  0.005922     4   \n",
       "2018-01-01 04:25:00  ...  13458.713445   1.114205   0.807456  0.001567     4   \n",
       "2018-01-01 04:30:00  ...  13482.808067   1.337812   0.790943  0.001143     4   \n",
       "2018-01-01 04:35:00  ...  13507.396874   1.373343   0.753596  0.001238     4   \n",
       "2018-01-01 04:40:00  ...  13517.326502   0.989930   0.925526  0.003373     4   \n",
       "2018-01-01 04:45:00  ...  13529.381900   0.897351   0.756818 -0.000549     4   \n",
       "2018-01-01 04:50:00  ...  13590.458730   1.361757   0.932222  0.005779     4   \n",
       "\n",
       "                     weekday  hour_sin  hour_cos  weekday_sin  weekday_cos  \n",
       "datetime                                                                    \n",
       "2018-01-01 04:05:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:10:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:15:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:20:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:25:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:30:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:35:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:40:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:45:00        0  0.887885  0.460065          0.0          1.0  \n",
       "2018-01-01 04:50:00        0  0.887885  0.460065          0.0          1.0  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_btc.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 19:17:32.328369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 19:17:32.328623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 19:17:32.328778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 19:17:32.764221: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 19:17:32.764426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 19:17:32.764587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 19:17:32.764726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20720 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_dataset_2 = tf.keras.utils.timeseries_dataset_from_array(train_examples[:-sequence_length], targets=train_labels[sequence_length-1:],\n",
    "                                                            sequence_length=sequence_length, sequence_stride=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 10, 41)\n",
      "tf.Tensor(\n",
      "[[ 1.34477300e+04  1.34550500e+04  1.33700000e+04  1.34000000e+04\n",
      "   2.04431160e+01  1.34325840e+04  1.34293603e+04  1.22642003e+03\n",
      "   1.34770470e+04  1.34382648e+04  4.16125785e+03  1.34431147e+04\n",
      "   1.34325903e+04  6.65346593e+03  1.34082405e+04  1.34271539e+04\n",
      "   9.36465738e+03  1.34322132e+04  1.34322132e+04  1.09155742e+04\n",
      "   7.81052277e+00  1.04106075e+00  6.76946202e+00  4.78585181e+01\n",
      "   4.65721630e+01  4.08405452e+01  4.14371339e+01  4.73607144e+01\n",
      "  -6.57608865e+01  1.33699378e+04  1.34325840e+04  1.34952302e+04\n",
      "   9.32749526e-01  2.39936265e-01 -2.00715725e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.33999900e+04  1.34274800e+04  1.33221500e+04  1.33517100e+04\n",
      "   3.25282880e+01  1.34049340e+04  1.34034769e+04  1.08291653e+03\n",
      "   1.34612180e+04  1.34225275e+04  5.50769017e+03  1.34445500e+04\n",
      "   1.34224803e+04  6.33701389e+03  1.34114260e+04  1.34199687e+04\n",
      "   8.76123483e+03  1.34272474e+04  1.34290562e+04  1.04481333e+04\n",
      "   4.74990227e-01 -5.03557744e+00  5.51056766e+00  4.43916429e+01\n",
      "   4.17220985e+01  3.30457735e+01  3.36078303e+01  4.05880674e+01\n",
      "  -8.07918573e+01  1.33460669e+04  1.34049340e+04  1.34638011e+04\n",
      "   8.78289713e-01  4.79306802e-02 -3.60373134e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.33549900e+04  1.33899800e+04  1.33235500e+04  1.33300500e+04\n",
      "   3.64745700e+01  1.33837480e+04  1.33790012e+04  1.68279812e+03\n",
      "   1.34379860e+04  1.34057134e+04  5.68280783e+03  1.34470193e+04\n",
      "   1.34109265e+04  5.62661491e+03  1.34169285e+04  1.34114051e+04\n",
      "   7.14926587e+03  1.34227568e+04  1.34251736e+04  1.02894694e+04\n",
      "  -7.00549812e+00 -1.00128526e+01  3.00735451e+00  4.28908207e+01\n",
      "   3.96635035e+01  2.99672578e+01  1.87265619e+01  3.12571754e+01\n",
      "  -9.72675706e+01  1.33103658e+04  1.33837480e+04  1.34571302e+04\n",
      "   1.09658738e+00  1.34121309e-01 -1.62226411e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.33369800e+04  1.34100000e+04  1.33310000e+04  1.34089900e+04\n",
      "   1.76102420e+01  1.33835400e+04  1.33889975e+04  1.66934780e+03\n",
      "   1.34198870e+04  1.34063092e+04  2.84534716e+03  1.34509520e+04\n",
      "   1.34106844e+04  5.04100713e+03  1.34213240e+04  1.34111750e+04\n",
      "   6.64872252e+03  1.34198136e+04  1.34245390e+04  9.92136042e+03\n",
      "  -6.48923688e+00 -7.59727311e+00  1.10803623e+00  4.95811068e+01\n",
      "   4.97113099e+01  5.02404390e+01  1.73255144e+01  2.32199689e+01\n",
      "  -6.99640288e+01  1.33104516e+04  1.33835400e+04  1.34566284e+04\n",
      "   1.09221314e+00  6.74104256e-01  5.92195828e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.34089900e+04  1.34498900e+04  1.33913100e+04  1.34300000e+04\n",
      "   1.64783250e+01  1.33841500e+04  1.34026650e+04  1.73740855e+03\n",
      "   1.34183670e+04  1.34106166e+04  2.78294947e+03  1.34499527e+04\n",
      "   1.34130989e+04  5.06875434e+03  1.34245245e+04  1.34129679e+04\n",
      "   6.48075186e+03  1.34198032e+04  1.34247531e+04  9.92113859e+03\n",
      "  -4.33479589e+00 -4.35426569e+00  1.94698051e-02  5.12190638e+01\n",
      "   5.20716266e+01  5.44516198e+01  2.33570836e+01  1.98030533e+01\n",
      "  -6.26971500e+01  1.33095866e+04  1.33841500e+04  1.34587134e+04\n",
      "   1.11420516e+00  8.07456287e-01  1.56685925e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.34299900e+04  1.34609000e+04  1.34019400e+04  1.34453500e+04\n",
      "   2.40845080e+01  1.33932200e+04  1.34168933e+04  2.50813180e+03\n",
      "   1.34129020e+04  1.34169318e+04  2.09022428e+03  1.34491047e+04\n",
      "   1.34171303e+04  5.06479054e+03  1.34306410e+04  1.34160519e+04\n",
      "   5.92192588e+03  1.34199114e+04  1.34255608e+04  9.92617048e+03\n",
      "  -1.37294273e+00 -1.11393003e+00 -2.59012703e-01  5.24348715e+01\n",
      "   5.38307355e+01  5.75977711e+01  3.66502951e+01  2.57776311e+01\n",
      "  -5.73879358e+01  1.33036319e+04  1.33932200e+04  1.34828081e+04\n",
      "   1.33781222e+00  7.90942766e-01  1.14296351e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.34462500e+04  1.34770000e+04  1.34221600e+04  1.34620000e+04\n",
      "   1.63700980e+01  1.34152780e+04  1.34319289e+04  2.65183967e+03\n",
      "   1.34101060e+04  1.34251260e+04  1.68961340e+03  1.34459047e+04\n",
      "   1.34227390e+04  4.80082254e+03  1.34372320e+04  1.34204279e+04\n",
      "   5.39677582e+03  1.34187290e+04  1.34269898e+04  9.75185142e+03\n",
      "   2.29144869e+00  2.04036911e+00  2.51079575e-01  5.37805162e+01\n",
      "   5.57865074e+01  6.10955552e+01  4.27764570e+01  3.42612786e+01\n",
      "  -5.15855432e+01  1.33231591e+04  1.34152780e+04  1.35073969e+04\n",
      "   1.37334275e+00  7.53596239e-01  1.23834634e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.34740000e+04  1.35500000e+04  1.34740000e+04  1.35074100e+04\n",
      "   2.84890020e+01  1.34507500e+04  1.34570893e+04  1.38513455e+03\n",
      "   1.34172490e+04  1.34400867e+04  2.61054452e+03  1.34422407e+04\n",
      "   1.34333229e+04  4.08777674e+03  1.34479520e+04  1.34287119e+04\n",
      "   4.44028100e+03  1.34185772e+04  1.34301436e+04  9.72317922e+03\n",
      "   8.75874739e+00  6.80613425e+00  1.95261314e+00  5.73263883e+01\n",
      "   6.08164578e+01  6.93659648e+01  5.29781963e+01  4.41349828e+01\n",
      "  -3.20919321e+01  1.33841735e+04  1.34507500e+04  1.35173265e+04\n",
      "   9.89929953e-01  9.25525513e-01  3.37319863e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.35074100e+04  1.35889900e+04  1.34800100e+04  1.34999900e+04\n",
      "   3.38039130e+01  1.34689500e+04  1.34713895e+04  1.14125455e+03\n",
      "   1.34262450e+04  1.34509782e+04  3.27550885e+03  1.34362413e+04\n",
      "   1.34416563e+04  2.72836208e+03  1.34554515e+04  1.34355003e+04\n",
      "   4.01862358e+03  1.34192938e+04  1.34328826e+04  9.81551752e+03\n",
      "   1.31339957e+01  8.94510604e+00  4.18888965e+00  5.65627884e+01\n",
      "   5.95857327e+01  6.65902669e+01  6.09897348e+01  5.22481294e+01\n",
      "  -3.33533203e+01  1.34085181e+04  1.34689500e+04  1.35293819e+04\n",
      "   8.97351318e-01  7.56818004e-01 -5.49328110e-04  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.34999900e+04  1.35789300e+04  1.34654100e+04  1.35780000e+04\n",
      "   1.74365320e+01  1.34985500e+04  1.35069263e+04  2.63975455e+03\n",
      "   1.34413500e+04  1.34740731e+04  5.58078360e+03  1.34450947e+04\n",
      "   1.34586992e+04  4.07404346e+03  1.34621020e+04  1.34490717e+04\n",
      "   4.75673457e+03  1.34214456e+04  1.34385735e+04  1.02715028e+04\n",
      "   2.26352416e+01  1.47570815e+01  7.87816003e+00  6.22552362e+01\n",
      "   6.73128983e+01  7.77984752e+01  7.68120582e+01  6.35933298e+01\n",
      "  -4.11857293e+00  1.34066413e+04  1.34985500e+04  1.35904587e+04\n",
      "   1.36175707e+00  9.32222273e-01  5.77852280e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]], shape=(10, 41), dtype=float64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "(128,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 19:17:33.364643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_13' with dtype int32\n",
      "\t [[{{node Placeholder/_13}}]]\n",
      "2023-07-01 19:17:33.365164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype int32 and shape [551738]\n",
      "\t [[{{node Placeholder/_8}}]]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_dataset_2):\n",
    "  if i == 0:\n",
    "    inputs, targets = batch\n",
    "    print(inputs.shape)\n",
    "    print(inputs[0, :, :])\n",
    "    print(targets[0])\n",
    "    print(targets.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 15:47:47.868121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 15:47:47.873199: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 15:47:47.873393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 15:47:47.874295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 15:47:47.874466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 15:47:47.874647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 15:47:48.294093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 15:47:48.294305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 15:47:48.294466: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-01 15:47:48.294621: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 845 MB memory:  -> device: 0, name: NVIDIA A10G, pci bus id: 0000:00:1e.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example:  tf.Tensor(\n",
      "[ 1.34477300e+04  1.34550500e+04  1.33700000e+04  1.34000000e+04\n",
      "  2.04431160e+01  1.34325840e+04  1.34293603e+04  1.22642003e+03\n",
      "  1.34770470e+04  1.34382648e+04  4.16125785e+03  1.34431147e+04\n",
      "  1.34325903e+04  6.65346593e+03  1.34082405e+04  1.34271539e+04\n",
      "  9.36465738e+03  1.34322132e+04  1.34322132e+04  1.09155742e+04\n",
      "  7.81052277e+00  1.04106075e+00  6.76946202e+00  4.78585181e+01\n",
      "  4.65721630e+01  4.08405452e+01  4.14371339e+01  4.73607144e+01\n",
      " -6.57608865e+01  1.33699378e+04  1.34325840e+04  1.34952302e+04\n",
      "  9.32749526e-01  2.39936265e-01 -2.00715725e-03  4.00000000e+00\n",
      "  0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "  1.00000000e+00], shape=(41,), dtype=float64)\n",
      "label:  tf.Tensor(0.9963962686567164, shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 15:47:52.115615: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [551757]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "    print('example: ', example)\n",
    "    print('label: ', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.34477300e+04  1.34550500e+04  1.33700000e+04  1.34000000e+04\n",
      "   2.04431160e+01  1.34325840e+04  1.34293603e+04  1.22642003e+03\n",
      "   1.34770470e+04  1.34382648e+04  4.16125785e+03  1.34431147e+04\n",
      "   1.34325903e+04  6.65346593e+03  1.34082405e+04  1.34271539e+04\n",
      "   9.36465738e+03  1.34322132e+04  1.34322132e+04  1.09155742e+04\n",
      "   7.81052277e+00  1.04106075e+00  6.76946202e+00  4.78585181e+01\n",
      "   4.65721630e+01  4.08405452e+01  4.14371339e+01  4.73607144e+01\n",
      "  -6.57608865e+01  1.33699378e+04  1.34325840e+04  1.34952302e+04\n",
      "   9.32749526e-01  2.39936265e-01 -2.00715725e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.33999900e+04  1.34274800e+04  1.33221500e+04  1.33517100e+04\n",
      "   3.25282880e+01  1.34049340e+04  1.34034769e+04  1.08291653e+03\n",
      "   1.34612180e+04  1.34225275e+04  5.50769017e+03  1.34445500e+04\n",
      "   1.34224803e+04  6.33701389e+03  1.34114260e+04  1.34199687e+04\n",
      "   8.76123483e+03  1.34272474e+04  1.34290562e+04  1.04481333e+04\n",
      "   4.74990227e-01 -5.03557744e+00  5.51056766e+00  4.43916429e+01\n",
      "   4.17220985e+01  3.30457735e+01  3.36078303e+01  4.05880674e+01\n",
      "  -8.07918573e+01  1.33460669e+04  1.34049340e+04  1.34638011e+04\n",
      "   8.78289713e-01  4.79306802e-02 -3.60373134e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]] [0.99639627 0.99837774]\n",
      "[[ 1.33549900e+04  1.33899800e+04  1.33235500e+04  1.33300500e+04\n",
      "   3.64745700e+01  1.33837480e+04  1.33790012e+04  1.68279812e+03\n",
      "   1.34379860e+04  1.34057134e+04  5.68280783e+03  1.34470193e+04\n",
      "   1.34109265e+04  5.62661491e+03  1.34169285e+04  1.34114051e+04\n",
      "   7.14926587e+03  1.34227568e+04  1.34251736e+04  1.02894694e+04\n",
      "  -7.00549812e+00 -1.00128526e+01  3.00735451e+00  4.28908207e+01\n",
      "   3.96635035e+01  2.99672578e+01  1.87265619e+01  3.12571754e+01\n",
      "  -9.72675706e+01  1.33103658e+04  1.33837480e+04  1.34571302e+04\n",
      "   1.09658738e+00  1.34121309e-01 -1.62226411e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.33369800e+04  1.34100000e+04  1.33310000e+04  1.34089900e+04\n",
      "   1.76102420e+01  1.33835400e+04  1.33889975e+04  1.66934780e+03\n",
      "   1.34198870e+04  1.34063092e+04  2.84534716e+03  1.34509520e+04\n",
      "   1.34106844e+04  5.04100713e+03  1.34213240e+04  1.34111750e+04\n",
      "   6.64872252e+03  1.34198136e+04  1.34245390e+04  9.92136042e+03\n",
      "  -6.48923688e+00 -7.59727311e+00  1.10803623e+00  4.95811068e+01\n",
      "   4.97113099e+01  5.02404390e+01  1.73255144e+01  2.32199689e+01\n",
      "  -6.99640288e+01  1.33104516e+04  1.33835400e+04  1.34566284e+04\n",
      "   1.09221314e+00  6.74104256e-01  5.92195828e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]] [1.00592196 1.00156686]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 15:48:12.838317: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [551757]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-07-01 15:48:12.838589: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [551757]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "batches = train_dataset.batch(2, drop_remainder=True)\n",
    "\n",
    "for batch in batches.take(2):\n",
    "  print(batch[0].numpy(), batch[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99639627, 0.99837774, 1.00592196, 1.00156686, 1.00114296,\n",
       "       1.00123835, 1.0033732 , 0.99945067, 1.00577852, 1.00169465])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_1_step(batch_x, batch_y):\n",
    "  # Shift features and labels one step relative to each other.\n",
    "  return batch_x, batch_y[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dense_1_step = batches.map(dense_1_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.map_op._MapDataset"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predict_dense_1_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.34477300e+04  1.34550500e+04  1.33700000e+04  1.34000000e+04\n",
      "   2.04431160e+01  1.34325840e+04  1.34293603e+04  1.22642003e+03\n",
      "   1.34770470e+04  1.34382648e+04  4.16125785e+03  1.34431147e+04\n",
      "   1.34325903e+04  6.65346593e+03  1.34082405e+04  1.34271539e+04\n",
      "   9.36465738e+03  1.34322132e+04  1.34322132e+04  1.09155742e+04\n",
      "   7.81052277e+00  1.04106075e+00  6.76946202e+00  4.78585181e+01\n",
      "   4.65721630e+01  4.08405452e+01  4.14371339e+01  4.73607144e+01\n",
      "  -6.57608865e+01  1.33699378e+04  1.34325840e+04  1.34952302e+04\n",
      "   9.32749526e-01  2.39936265e-01 -2.00715725e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.33999900e+04  1.34274800e+04  1.33221500e+04  1.33517100e+04\n",
      "   3.25282880e+01  1.34049340e+04  1.34034769e+04  1.08291653e+03\n",
      "   1.34612180e+04  1.34225275e+04  5.50769017e+03  1.34445500e+04\n",
      "   1.34224803e+04  6.33701389e+03  1.34114260e+04  1.34199687e+04\n",
      "   8.76123483e+03  1.34272474e+04  1.34290562e+04  1.04481333e+04\n",
      "   4.74990227e-01 -5.03557744e+00  5.51056766e+00  4.43916429e+01\n",
      "   4.17220985e+01  3.30457735e+01  3.36078303e+01  4.05880674e+01\n",
      "  -8.07918573e+01  1.33460669e+04  1.34049340e+04  1.34638011e+04\n",
      "   8.78289713e-01  4.79306802e-02 -3.60373134e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.33549900e+04  1.33899800e+04  1.33235500e+04  1.33300500e+04\n",
      "   3.64745700e+01  1.33837480e+04  1.33790012e+04  1.68279812e+03\n",
      "   1.34379860e+04  1.34057134e+04  5.68280783e+03  1.34470193e+04\n",
      "   1.34109265e+04  5.62661491e+03  1.34169285e+04  1.34114051e+04\n",
      "   7.14926587e+03  1.34227568e+04  1.34251736e+04  1.02894694e+04\n",
      "  -7.00549812e+00 -1.00128526e+01  3.00735451e+00  4.28908207e+01\n",
      "   3.96635035e+01  2.99672578e+01  1.87265619e+01  3.12571754e+01\n",
      "  -9.72675706e+01  1.33103658e+04  1.33837480e+04  1.34571302e+04\n",
      "   1.09658738e+00  1.34121309e-01 -1.62226411e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.33369800e+04  1.34100000e+04  1.33310000e+04  1.34089900e+04\n",
      "   1.76102420e+01  1.33835400e+04  1.33889975e+04  1.66934780e+03\n",
      "   1.34198870e+04  1.34063092e+04  2.84534716e+03  1.34509520e+04\n",
      "   1.34106844e+04  5.04100713e+03  1.34213240e+04  1.34111750e+04\n",
      "   6.64872252e+03  1.34198136e+04  1.34245390e+04  9.92136042e+03\n",
      "  -6.48923688e+00 -7.59727311e+00  1.10803623e+00  4.95811068e+01\n",
      "   4.97113099e+01  5.02404390e+01  1.73255144e+01  2.32199689e+01\n",
      "  -6.99640288e+01  1.33104516e+04  1.33835400e+04  1.34566284e+04\n",
      "   1.09221314e+00  6.74104256e-01  5.92195828e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.34089900e+04  1.34498900e+04  1.33913100e+04  1.34300000e+04\n",
      "   1.64783250e+01  1.33841500e+04  1.34026650e+04  1.73740855e+03\n",
      "   1.34183670e+04  1.34106166e+04  2.78294947e+03  1.34499527e+04\n",
      "   1.34130989e+04  5.06875434e+03  1.34245245e+04  1.34129679e+04\n",
      "   6.48075186e+03  1.34198032e+04  1.34247531e+04  9.92113859e+03\n",
      "  -4.33479589e+00 -4.35426569e+00  1.94698051e-02  5.12190638e+01\n",
      "   5.20716266e+01  5.44516198e+01  2.33570836e+01  1.98030533e+01\n",
      "  -6.26971500e+01  1.33095866e+04  1.33841500e+04  1.34587134e+04\n",
      "   1.11420516e+00  8.07456287e-01  1.56685925e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.34299900e+04  1.34609000e+04  1.34019400e+04  1.34453500e+04\n",
      "   2.40845080e+01  1.33932200e+04  1.34168933e+04  2.50813180e+03\n",
      "   1.34129020e+04  1.34169318e+04  2.09022428e+03  1.34491047e+04\n",
      "   1.34171303e+04  5.06479054e+03  1.34306410e+04  1.34160519e+04\n",
      "   5.92192588e+03  1.34199114e+04  1.34255608e+04  9.92617048e+03\n",
      "  -1.37294273e+00 -1.11393003e+00 -2.59012703e-01  5.24348715e+01\n",
      "   5.38307355e+01  5.75977711e+01  3.66502951e+01  2.57776311e+01\n",
      "  -5.73879358e+01  1.33036319e+04  1.33932200e+04  1.34828081e+04\n",
      "   1.33781222e+00  7.90942766e-01  1.14296351e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.34462500e+04  1.34770000e+04  1.34221600e+04  1.34620000e+04\n",
      "   1.63700980e+01  1.34152780e+04  1.34319289e+04  2.65183967e+03\n",
      "   1.34101060e+04  1.34251260e+04  1.68961340e+03  1.34459047e+04\n",
      "   1.34227390e+04  4.80082254e+03  1.34372320e+04  1.34204279e+04\n",
      "   5.39677582e+03  1.34187290e+04  1.34269898e+04  9.75185142e+03\n",
      "   2.29144869e+00  2.04036911e+00  2.51079575e-01  5.37805162e+01\n",
      "   5.57865074e+01  6.10955552e+01  4.27764570e+01  3.42612786e+01\n",
      "  -5.15855432e+01  1.33231591e+04  1.34152780e+04  1.35073969e+04\n",
      "   1.37334275e+00  7.53596239e-01  1.23834634e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.34740000e+04  1.35500000e+04  1.34740000e+04  1.35074100e+04\n",
      "   2.84890020e+01  1.34507500e+04  1.34570893e+04  1.38513455e+03\n",
      "   1.34172490e+04  1.34400867e+04  2.61054452e+03  1.34422407e+04\n",
      "   1.34333229e+04  4.08777674e+03  1.34479520e+04  1.34287119e+04\n",
      "   4.44028100e+03  1.34185772e+04  1.34301436e+04  9.72317922e+03\n",
      "   8.75874739e+00  6.80613425e+00  1.95261314e+00  5.73263883e+01\n",
      "   6.08164578e+01  6.93659648e+01  5.29781963e+01  4.41349828e+01\n",
      "  -3.20919321e+01  1.33841735e+04  1.34507500e+04  1.35173265e+04\n",
      "   9.89929953e-01  9.25525513e-01  3.37319863e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.35074100e+04  1.35889900e+04  1.34800100e+04  1.34999900e+04\n",
      "   3.38039130e+01  1.34689500e+04  1.34713895e+04  1.14125455e+03\n",
      "   1.34262450e+04  1.34509782e+04  3.27550885e+03  1.34362413e+04\n",
      "   1.34416563e+04  2.72836208e+03  1.34554515e+04  1.34355003e+04\n",
      "   4.01862358e+03  1.34192938e+04  1.34328826e+04  9.81551752e+03\n",
      "   1.31339957e+01  8.94510604e+00  4.18888965e+00  5.65627884e+01\n",
      "   5.95857327e+01  6.65902669e+01  6.09897348e+01  5.22481294e+01\n",
      "  -3.33533203e+01  1.34085181e+04  1.34689500e+04  1.35293819e+04\n",
      "   8.97351318e-01  7.56818004e-01 -5.49328110e-04  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [ 1.34999900e+04  1.35789300e+04  1.34654100e+04  1.35780000e+04\n",
      "   1.74365320e+01  1.34985500e+04  1.35069263e+04  2.63975455e+03\n",
      "   1.34413500e+04  1.34740731e+04  5.58078360e+03  1.34450947e+04\n",
      "   1.34586992e+04  4.07404346e+03  1.34621020e+04  1.34490717e+04\n",
      "   4.75673457e+03  1.34214456e+04  1.34385735e+04  1.02715028e+04\n",
      "   2.26352416e+01  1.47570815e+01  7.87816003e+00  6.22552362e+01\n",
      "   6.73128983e+01  7.77984752e+01  7.68120582e+01  6.35933298e+01\n",
      "  -4.11857293e+00  1.34066413e+04  1.34985500e+04  1.35904587e+04\n",
      "   1.36175707e+00  9.32222273e-01  5.77852280e-03  4.00000000e+00\n",
      "   0.00000000e+00  8.87885218e-01  4.60065038e-01  0.00000000e+00\n",
      "   1.00000000e+00]]  =>  1.0016946531153337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 15:33:19.610162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [551757]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "for features, label in predict_dense_1_step.take(1):\n",
    "  print(features.numpy(), \" => \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 19:17:38.038241: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-01 19:17:38.039431: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-01 19:17:38.040254: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-01 19:17:38.200183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-01 19:17:38.201274: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-01 19:17:38.202193: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-01 19:17:38.351018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-01 19:17:38.352253: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-01 19:17:38.353085: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "build_model = getattr(importlib.import_module(f'ml_investing_wne.tf_models.lstm'),'build_model')\n",
    "model = build_model(input_shape=(10, 41), nb_classes=config.nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-01 19:17:43.877615: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-01 19:17:43.879107: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-01 19:17:43.880115: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-01 19:17:44.021213: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-01 19:17:44.022454: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-01 19:17:44.023550: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-01 19:17:44.165394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-01 19:17:44.166790: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-01 19:17:44.167688: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-01 19:17:45.085236: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-01 19:17:45.086712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-01 19:17:45.087665: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-01 19:17:45.227676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-01 19:17:45.228668: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-01 19:17:45.229651: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-01 19:17:45.371175: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-01 19:17:45.372479: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-01 19:17:45.373591: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-01 19:17:46.943182: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.0.5 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-07-01 19:17:46.944006: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at cudnn_rnn_ops.cc:1554 : UNKNOWN: Fail to find the dnn implementation.\n",
      "2023-07-01 19:17:46.944054: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: Fail to find the dnn implementation.\n",
      "\t [[{{node CudnnRNN}}]]\n",
      "2023-07-01 19:17:46.944137: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: {{function_node __forward_gpu_lstm_with_fallback_5809_specialized_for_sequential_lstm_PartitionedCall_at___inference_train_function_8587}} {{function_node __forward_gpu_lstm_with_fallback_5809_specialized_for_sequential_lstm_PartitionedCall_at___inference_train_function_8587}} Fail to find the dnn implementation.\n",
      "\t [[{{node CudnnRNN}}]]\n",
      "\t [[sequential/lstm/PartitionedCall]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nFail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/PartitionedCall]] [Op:__inference_train_function_8587]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/SageMaker/.cs/conda/envs/codeserver_py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/SageMaker/.cs/conda/envs/codeserver_py39/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nFail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/PartitionedCall]] [Op:__inference_train_function_8587]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset_2, epochs=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('codeserver_py39': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca522a4f3a95a8cc19c0c49aa2b52717208ab4d9caac282bf163cf809ab5536"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
